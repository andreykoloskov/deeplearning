{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Все места, где нужно дописать код отмечены TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание и подготовка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем текстовые данные: все файлы должны лежать в одной папке data. \n",
    "# Проверьте, что у вас все хорошо с кодировками и текст нормально считывается.\n",
    "data = \"\"\n",
    "\n",
    "for fname in os.listdir(\"data\"):\n",
    "    with open(\"data/\"+fname) as fin:\n",
    "        text = fin.read().decode('cp1251')\n",
    "        data += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\r\n",
      "\r\n",
      "\r\n",
      " Устав патрульно-постовой службы милиции общественной безопасности Российской Федерации\r\n",
      "\r\n",
      " Утвержден приказом Министра внутренних дел Российской Фед\n"
     ]
    }
   ],
   "source": [
    "print data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для дальнейшей работы нам нужно текст перевести в числовой формат.\n",
    "chars = list(set(data))\n",
    "VOCAB_SIZE = len(chars)\n",
    "\n",
    "char_to_id = { ch:id for id,ch in enumerate(chars) }\n",
    "id_to_char = { id:ch for id,ch in enumerate(chars) }\n",
    "data_ids = [char_to_id[ch] for ch in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Необходимые константы\n",
    "NUM_EPOCHS = 10\n",
    "NUM_BATCHES = 1000\n",
    "BATCH_SIZE = 100\n",
    "SEQ_LEN = 20\n",
    "LEARNING_RATE = 0.01\n",
    "GRAD_CLIP = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе обучения мы будем для каждого символа входной последовательности предсказывать следующий символ. Таким образом на вход сети мы будем подавать последовательности длины SEQ_LEN и получать на выходе последовательности той же длины, но со сдвигом на один символ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_batch(source):\n",
    "    \"\"\"Функция, которая генерирует batch из BATCH_SIZE случайных подстрок текста source. \n",
    "    Каждая подстрока должна иметь длину SEQ_LEN.\n",
    "    \n",
    "    source - массив целых чисел - номеров символов в тексте (пример - data_ids)\n",
    "    \n",
    "    Вернуть нужно кортеж (X,y), где\n",
    "    X - матрица, в которой каждая строка - подстрока длины SEQ_LEN (подается на вход сети)\n",
    "    y - матрица, в которой каждая строка - подстрока длины SEQ_LEN, (ожидается на выходе сети)\n",
    "    Таким образом, каждая строка в y должна соответсвовать строке в X со сдвигом на один символ вправо.\n",
    "    Например, если X[0]='hell', то y[0]='ello'\n",
    "    \n",
    "    Убедитесь, что вы генерируете X и y, которые правильно соответствуют друг другу.\n",
    "    Также убедитесь, что ваша функция не вылезает за край текста (самое начало или конец текста).\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "органов указанного ф\n",
      "рганов указанного фе\n"
     ]
    }
   ],
   "source": [
    "a,b = generate_random_batch(data_ids)\n",
    "print ''.join(id_to_char[id] for id in a[0,:])\n",
    "print ''.join(id_to_char[id] for id in b[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе тестирования мы будем предсказывать следующий символ по SEQ_LEN предыдущих. \n",
    "Генерировать очередной символ в тестовой посдедовательнсоти можно разными способами:\n",
    "1. max_sample_fn: брать символ с максимальной вероятностью\n",
    "2. proportional_sample_fn: генерировать символ пропорционально вероятности\n",
    "3. alpha_sample_fn: генерировать символ пропорционально вероятности со следующей предобраоткой: \n",
    "    logprobs/alpha, где alpha - \"жадность\" из (0,1] - чем меньше, тем ближе генерация к выбору максимума\n",
    "    после взятия экспоненты такие вероятности нужно перенормировать\n",
    "\n",
    "Для устойчивости вычислений наша сеть будет выдавать не вероятности, а их логарифмы, поэтому не забывайте в нужных местах брать от них exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_sample_fn(logprobs):\n",
    "    return np.argmax(logprobs) \n",
    "\n",
    "def proportional_sample_fn(logprobs):\n",
    "    # TODO\n",
    "\n",
    "def alpha_sample_fn(logprobs, alpha):\n",
    "    # TODO\n",
    "\n",
    "def generate_seed():\n",
    "    \"\"\"Функция выбирает случайное начало поседовательности из data, \n",
    "    которую мы потом можем продолжать с помощью нейросети.\n",
    "    \"\"\"\n",
    "    start = np.random.randint(0,len(data)-SEQ_LEN)\n",
    "    seed_phrase = data[start:start+SEQ_LEN]\n",
    "    return seed_phrase\n",
    "\n",
    "def generate_sample(logprobs_fn,sample_fn,seed_phrase,N=100):\n",
    "    \"\"\"Функция генерирует случайный текст при помощи нейросети и печатает его\n",
    "    \n",
    "    logprobs_fn - функция, которая по входной последовательности длины SEQ_LEN \n",
    "        предсказывает логарифмы вероятностей посдледующего символа (см. функцию train)\n",
    "    sample_fn - функция, выбирающая следующий символ одним из способов, описанных выше\n",
    "    seed_phrase - начальная фраза, с которой мы начинаем генерировать\n",
    "    N - размер генерируемого текста\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    print(random_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Технические вещи\n",
    "\n",
    "# Вспомогательная функция для запаковки результата обучения \n",
    "def pack(err, network, logprobs_fn):\n",
    "    return {'err':err, \n",
    "        'network':network,\n",
    "        'logprobs_fn':logprobs_fn\n",
    "           } \n",
    "\n",
    "# numerically stable log-softmax with crossentropy\n",
    "def logsoftmax(x):\n",
    "    xdev = x-x.max(2,keepdim=True)[0]\n",
    "    lsm = xdev - torch.exp(xdev).sum(dim=2, keepdim=True).log()\n",
    "    return lsm\n",
    "\n",
    "def lsmCE(x,y):\n",
    "    return -torch.clamp(x,-20,0).gather(2, y.unsqueeze(2)).squeeze().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Класс задает простейшую рекуррентную сеть, которая принимает на вход батч размера [BATCH_SIZE, SEQ_LEN] \n",
    "    и применяет к нему следующие преобразования:\n",
    "    \n",
    "    1. Embedding для перевода кодировки символов в нормальное представление: VOCAB_SIZE -> emb_size\n",
    "    2. Рекуррентный слой c n_hidden элементов на скрытом слое.\n",
    "    3. Полносвязный слой n_hidden -> VOCAB_SIZE с logsoftmax в качестве нелинейности.\n",
    "    \n",
    "    В итоге на выход сеть должна возвращать ответ размера [BATCH_SIZE, SEQ_LEN, VOCAB_SIZE] \n",
    "    \n",
    "    * Обратите внимание на параметр batch_first у рекуррентного слоя.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, emb_size = 40, n_hidden = 100):\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, text):\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_ids, emb_size, n_hidden, show = False):\n",
    "    \"\"\"Функция обучает нейросеть по данным data_ids\n",
    "    Следует обратить внимание на следующее:\n",
    "    1. Сеть будем учить NUM_EPOCHS эпох, в каждой из которых будет NUM_BATCHES батчей\n",
    "    2. Для того, чтобы следить за процессом обучения будем считать средний loss \n",
    "        на всех батчах в эпохе и сохранять его в массив err. Также будем генерировать \n",
    "        последовательности из случайных seeds после каждой эпохи, для этого нужна будет функция logprobs_fn,\n",
    "        которая по входу х размера [1, SEQ_LEN] будет выдавать вектор логарифмов вероятностей \n",
    "        для последующего символа размера [1, VOCAB_SIZE]. \n",
    "        Например, если x='hell', то нас интересует каким будет символ после второго l. \n",
    "    3. Так как мы вместо softmax используем logsoftmax, то в качестве loss для сети нужно использовать lsmCE\n",
    "    4. Перед тем, как делать шаг по градиенту, шрадиент нужно ограничивать по норме значением GRAD_CLIP\n",
    "    \n",
    "    * Если вы используете GPU, то не забудьте все данные и саму сеть перенести на GPU.\n",
    "    \"\"\"\n",
    "    err=np.zeros(NUM_EPOCHS)\n",
    "\n",
    "    print(\"Building network ...\")\n",
    "    # Строим сеть и переносим ее на cuda, если нужно\n",
    "    # TODO\n",
    "    print(\"The network has {} params\".format(sum([x.data.numel() for x in net.parameters()])))\n",
    "    \n",
    "    # Задаем оптимизатор, рекомендуется использовать adam\n",
    "    # TODO\n",
    "        \n",
    "    def logprobs_fn(snippetIdx):\n",
    "        # TODO\n",
    "        \n",
    "    print(\"Training ...\")\n",
    "    for epoch in xrange(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        for batch in xrange(NUM_BATCHES):\n",
    "            # TODO\n",
    "\n",
    "        if show:\n",
    "            seed = generate_seed()\n",
    "            print \"Seed: '{}'\".format(seed.encode('utf-8'))\n",
    "            print \"Max sample:\"\n",
    "            generate_sample(logprobs_fn, max_sample_fn, seed)\n",
    "            print \"Proportional sample:\", \n",
    "            generate_sample(logprobs_fn, proportional_sample_fn, seed)\n",
    "        print(\"Epoch {} \\t loss = {:.4f} \\t time = {:.2f}s\".\n",
    "                      format(epoch, err[epoch], time.time() - start_time))\n",
    "             \n",
    "    return pack(err, net, logprobs_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как запускать обучение с большим числом итераций и длинными последовательностями, попробуйте запустить его на десяток итераций с последовательнсотямит по 5 символов и проверьте, что у вас генерируются какие-то вменяемые слоги. При этом достатояно использовать довольно маленькую сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n",
      "The network has 71182 params\n",
      "Training ...\n",
      "Epoch 0 \t loss = 2.4505 \t time = 4.84s\n",
      "Epoch 1 \t loss = 1.7952 \t time = 4.64s\n",
      "Epoch 2 \t loss = 1.5806 \t time = 4.62s\n",
      "Epoch 3 \t loss = 1.4649 \t time = 4.63s\n",
      "Epoch 4 \t loss = 1.3969 \t time = 4.64s\n",
      "Epoch 5 \t loss = 1.3532 \t time = 4.62s\n",
      "Epoch 6 \t loss = 1.3178 \t time = 4.63s\n",
      "Epoch 7 \t loss = 1.2906 \t time = 4.62s\n",
      "Epoch 8 \t loss = 1.2705 \t time = 4.65s\n",
      "Epoch 9 \t loss = 1.2560 \t time = 4.68s\n"
     ]
    }
   ],
   "source": [
    "model = train(data_ids, 40, 200, show = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим что из этого вышло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Каждый человек должен вознай или в соответствии с порядке, нех соответствии с принятия наследниками или подлежат исполнения потожный судебной статьи 19.5, статьями 19.20 настоящей статьи 118 настоящего Кодекса и лицами совершение возника\r\n",
      "\r\n",
      " 1. Права и правилами собственника определение осуществляющие порядке, после ино\n"
     ]
    }
   ],
   "source": [
    "seed = u\"Каждый человек должен\"\n",
    "alpha = 0.5\n",
    "sampling_fun = lambda x: alpha_sample_fn(x, alpha)\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(model['logprobs_fn'],sampling_fun,seed,result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В случае неповиновения\r\n",
      "\r\n",
      " 1. Проведение товаров и принятия в соответствии с принятия в порядке, об административного штрафа на путем о принятия при право граждан от двадцати до действия об административного правонарушении обращение предусмотрено должностных лиц – от десяти до трех действии содержащей судом или соответст\n"
     ]
    }
   ],
   "source": [
    "seed = u\"В случае неповиновения\"\n",
    "alpha = 0.5\n",
    "sampling_fun = lambda x: alpha_sample_fn(x, alpha)\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(model['logprobs_fn'],sampling_fun,seed,result_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные пункты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучение более сложной модели и контроль переобучения. Попробуйте подобрать хорошую модель RNN для данной задачи. Для этого  проанализируйте качество работы модели в зависимости от ее размеров, попробуйте использовать многослойную сеть. Также нужно проконтролировать переобучение моделей. Для этого можно выделить тестовый кусок из текста и смотреть на то, как меняется loss на нем в процессе обучения. Если на графиках видно переобучение, то стоит добавить dropout в модель (обычный dropout до, между и после рекуррентных слоев). \n",
    "2. LSTM и GRU архитектуры. Вместо обычной RNN попробуйте LSTM и GRU архитектуры и сравните получающиеся результаты для моделей нескольких разных размеров. Также сравните модели на данных с разной SEQ_LEN. \n",
    "4. Визуализация. Попробуйте провизуализировать результаты. Например, можно смотреть на то, какие буквы модель хорошо предсказывает, а в каких сильно не уверена. Это покажет что именно выучила модель лучше всего. Также можно попробовать смотреть на активации разных скрытых нейронов при прочтении текста (как у Андрея Карпатого).\n",
    "5. Более сложные данные. Попробуйте обучить модель на более структурированных данных, например коде. Используйте LSTM и GRU сети, они хорошо улавливают структуру в данных. Проанализируйте результаты: выделите нейроны, активации которых \"отвечают\" за структуру в данных. Этот пункт, пожалуй, стоит пробовать только если у вас есть нормальный GPU.\n",
    "6. Продвинутый дропаут. Запрограммировать RNN/LSTM с продвинутым дропаутом из (одним из 3, обсужденных на лекции). Сравнить с обычным вариантом дропаута по нерекуррентным связям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
